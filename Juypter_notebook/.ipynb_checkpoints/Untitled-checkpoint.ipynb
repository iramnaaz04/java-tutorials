{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\hp-pc\\miniconda3\\envs\\ashper\\lib\\site-packages (from keras) (1.19.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\hp-pc\\miniconda3\\envs\\ashper\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hp-pc\\miniconda3\\envs\\ashper\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\hp-pc\\miniconda3\\envs\\ashper\\lib\\site-packages (from keras) (1.5.2)\n",
      "Requirement already satisfied: six in c:\\users\\hp-pc\\miniconda3\\envs\\ashper\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\hp-pc\\Miniconda3\\envs\\ashper\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Juypter_notebook/Pattern_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2176c92f3e17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Juypter_notebook/Pattern_names'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0msub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'Juypter_notebook/Pattern_names'"
     ]
    }
   ],
   "source": [
    "# Processing training data\n",
    "# -> appending images in a list 'train_images'\n",
    "# -> appending labels in a list 'train_labels'\n",
    "\n",
    "train_images = []       \n",
    "train_labels = []\n",
    "shape = (200,200)  \n",
    "train_path = 'Pattern_names'\n",
    "\n",
    "for filename in os.listdir(train_path):\n",
    "    sub = train_path + '/' + filename\n",
    "    if (os.path.isdir(sub)):\n",
    "        for image in os.listdir(sub):\n",
    "            if image.split('.')[1] == 'png':\n",
    "                img = cv2.imread(os.path.join(sub,image))\n",
    "\n",
    "                # Spliting file names and storing the labels for image in list\n",
    "                train_labels.append(filename)\n",
    "\n",
    "                # Resize all images to a specific shape\n",
    "                img = cv2.resize(img,shape)\n",
    "\n",
    "                train_images.append(img)\n",
    "\n",
    "\n",
    "# Converting labels into One Hot encoded sparse matrix\n",
    "train_labels = pd.get_dummies(train_labels).values\n",
    "\n",
    "# Converting train_images to array\n",
    "train_images = np.array(train_images)\n",
    "\n",
    "# Splitting Training data into train and validation dataset\n",
    "x_train,x_val,y_train,y_val = train_test_split(train_images,train_labels,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labels[0])\n",
    "plt.imshow(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []       \n",
    "test_labels = []\n",
    "shape = (200,200)  \n",
    "test_path = '../input/fingerprints/fingerprints/'\n",
    "\n",
    "for filename in os.listdir(test_path):\n",
    "    sub = test_path + '/' + filename\n",
    "    if (os.path.isdir(sub)):\n",
    "        for image in os.listdir(sub):\n",
    "            if image.split('.')[1] == 'png':\n",
    "                img = cv2.imread(os.path.join(sub,image))\n",
    "\n",
    "                # Spliting file names and storing the labels for image in list\n",
    "                test_labels.append(filename)\n",
    "\n",
    "                # Resize all images to a specific shape\n",
    "                img = cv2.resize(img,shape)\n",
    "\n",
    "                test_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Conv2D(kernel_size=(3,3), filters=32, activation='tanh', input_shape=(200,200,3,)))\n",
    "model.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(Dense(15,activation='relu'))\n",
    "model.add(Dense(5,activation = 'softmax'))\n",
    "    \n",
    "model.compile(\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['acc'],\n",
    "              optimizer='adam'\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "history = model.fit(x_train,y_train,epochs=50,batch_size=50,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating model on validation data\n",
    "evaluate = model.evaluate(x_val,y_val)\n",
    "print(evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing predictions and the actual label\n",
    "checkImage = test_images[1:2]\n",
    "checklabel = test_labels[1:2]\n",
    "\n",
    "predict = model.predict(np.array(checkImage))\n",
    "\n",
    "output = { 0:'A',1:'L',2:'R',3:'T', 4:'W'}\n",
    "\n",
    "print(\"Actual :- \",checklabel)\n",
    "print(\"Predicted :- \",output[np.argmax(predict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(checkImage[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test_version1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
